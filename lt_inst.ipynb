{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4G_CAQR1nnm"
      },
      "outputs": [],
      "source": [
        "from IPython.utils import capture\n",
        "with capture.capture_output() as cap:\n",
        "  import os, subprocess, sys, fileinput\n",
        "  import concurrent.futures\n",
        "  from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "  from IPython.display import clear_output\n",
        "  from google.colab import drive\n",
        "  if not os.path.exists(\"/content/ltrain\"):\n",
        "    drive.mount('/content/drive')\n",
        "    %cd /content/\n",
        "    clear_output()\n",
        "    print(\"установка зависимостей\")\n",
        "    os.makedirs(\"/content/models\", exist_ok=True)\n",
        "    os.makedirs(\"/content/drive/MyDrive/LORA\", exist_ok=True)\n",
        "    base_path = '/content/drive/MyDrive/LORA/'\n",
        "    wget = \"wget -nv -t 10 --show-progress --progress=bar -q --content-disposition \"\n",
        "    debs = [\n",
        "      f\"{wget} 'https://civitai.com/api/download/models/127207?type=Model&format=SafeTensor&size=pruned&fp=fp16' -O /content/models/Juggernaut.safetensors\",\n",
        "      f\"{wget} 'https://civitai.com/api/download/models/143906?type=Model&format=SafeTensor&size=pruned&fp=fp16' -O /content/models/epiCRealism.safetensors\",\n",
        "      \"git clone https://github.com/PR0LAPSE/lora_colab ltrain\",\n",
        "      f\"{wget} https://huggingface.co/utnah/deps/resolve/main/db_deps.7z\",\n",
        "    ]\n",
        "    def colab_downgrade(deb):\n",
        "      subprocess.getoutput(deb)\n",
        "    with ThreadPoolExecutor(max_workers=len(debs)) as executor:\n",
        "      futures = [executor.submit(colab_downgrade, deb) for deb in debs]\n",
        "      for future in futures:\n",
        "        future.result()\n",
        "    !7z -bso0 -bd -mmt4 -slp -y x /content/db_deps.7z -o/usr/local/lib/python3.10/dist-packages > /dev/null 2>&1\n",
        "    !rm /content/db_deps.7z\n",
        "\n",
        "\n",
        "    wget = \"wget -nv -t 10 --show-progress --progress=bar:force -q --content-disposition\"\n",
        "    def from_repo(filename, path=None):\n",
        "        if path is not None:\n",
        "            get_ipython().system(f\"{wget} {filename} -P {path}\")\n",
        "        else:\n",
        "            get_ipython().system(f\"{wget} {filename}\")\n",
        "\n",
        "    from_repo(\"https://huggingface.co/2ch/colab/resolve/main/libtcmalloc_minimal.so.4\", \"/lib/\")\n",
        "    while (os.path.getsize('/lib/libtcmalloc_minimal.so.4') < 300000) or (not os.path.exists('/lib/libtcmalloc_minimal.so.4')):\n",
        "        from_repo(\"https://huggingface.co/2ch/colab/resolve/main/libtcmalloc_minimal.so.4\", \"/lib/\")\n",
        "\n",
        "    os.environ[\"LD_PRELOAD\"]='/lib/libtcmalloc_minimal.so.4'\n",
        "    os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"]='garbage_collection_threshold:0.9,max_split_size_mb:512'\n",
        "    os.environ[\"SAFETENSORS_FAST_GPU\"]='1'\n",
        "    os.environ[\"CUDA_MODULE_LOADING\"]=\"LAZY\"\n",
        "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
        "    os.environ.setdefault('ACCELERATE', 'True')\n",
        "    os.environ.setdefault('ATTN_PRECISION', 'fp16')\n",
        "    os.environ.setdefault('PYTORCH_CUDA_ALLOC_CONF', 'garbage_collection_threshold:0.8,max_split_size_mb:512')\n",
        "    os.environ.setdefault('CUDA_LAUNCH_BLOCKING', '0')\n",
        "    os.environ.setdefault('CUDA_CACHE_DISABLE', '0')\n",
        "    os.environ.setdefault('CUDA_AUTO_BOOST', '1')\n",
        "    os.environ.setdefault('CUDA_MODULE_LOADING', 'LAZY')\n",
        "    os.environ.setdefault('CUDA_DEVICE_DEFAULT_PERSISTING_L2_CACHE_PERCENTAGE_LIMIT', '0')\n",
        "    os.environ.setdefault('GRADIO_ANALYTICS_ENABLED', 'False')\n",
        "    os.environ.setdefault('NUMEXPR_MAX_THREADS', '16')\n",
        "    os.environ.setdefault('PYTHONHTTPSVERIFY', '0')\n",
        "    os.environ.setdefault('HF_HUB_DISABLE_TELEMETRY', '1')\n",
        "    os.environ.setdefault('UVICORN_TIMEOUT_KEEP_ALIVE', '60')\n",
        "\n",
        "    clear_output()\n",
        "    if загрузить_с_пк:\n",
        "      from google.colab import files\n",
        "      import shutil\n",
        "      folders = ['input', 'output', 'log', 'config']\n",
        "      for folder in folders:\n",
        "        os.makedirs(base_path + folder, exist_ok=True)\n",
        "      input_folder_path = base_path + folders[0]\n",
        "      print(f\"загрузка изображений в {input_folder_path}\")\n",
        "      uploaded = files.upload()\n",
        "      num_files = len([k for k in uploaded.keys() if '.txt' not in k])\n",
        "      CONST = 1500\n",
        "      if int(CONST / num_files) < step_limit:\n",
        "        num_f = step_limit\n",
        "      else:\n",
        "        num_f = int(CONST / num_files)\n",
        "      num_input = input_folder_path + f'/{num_f}_{trigger_word}'\n",
        "      os.makedirs(num_input, exist_ok=True)\n",
        "      for filename in uploaded.keys():\n",
        "        dst_path = os.path.join(num_input, filename)\n",
        "        shutil.move(filename, dst_path)\n",
        "  %cd /content/ltrain\n",
        "  if Ngrok_token!=\"\":\n",
        "    from pyngrok import ngrok, conf\n",
        "    ngrok.kill()\n",
        "    srv=ngrok.connect(7860, pyngrok_config=conf.PyngrokConfig(auth_token=Ngrok_token) , bind_tls=True).public_url\n",
        "    for line in fileinput.input('/content/ltrain/ltrain.py', inplace=True):\n",
        "      if line.strip().startswith(\"print('Load CSS...')\"):\n",
        "        line = f\"            print('Load CSS...')\\n            print('Running on ngrok URL:  {srv}')\\n\"\n",
        "      sys.stdout.write(line)\n",
        "  else:\n",
        "    for line in fileinput.input('/content/ltrain/ltrain.py', inplace=True):\n",
        "      if line.strip().startswith(\"print('Running on ngrok URL:\"):\n",
        "        line = f\"\"\n",
        "      sys.stdout.write(line)\n",
        "  clear_output()\n",
        "  !python /content/ltrain/ltrain.py > /content/out.txt"
      ]
    }
  ]
}